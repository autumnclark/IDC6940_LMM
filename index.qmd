---
title: "Analyzing Blood Pressure using Normal Linear Mixed Models"
subtitle: "An analysis of blood pressure "
author: "Autumn Clark and Alex Ottley (Advisor: Dr.Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!
:::

## Introduction

  In recent years, statistical models have become indispensable tools in understanding complex data structures across various fields, including biology, social sciences, economics, and medicine. One powerful class of models that has gained significant traction is the linear mixed model (LMM). Linear mixed models extend traditional linear regression by incorporating both fixed and random effects, making them well-suited for data with hierarchical or grouped structures. Unlike standard linear models, which assume that all observations are independent, linear mixed models allow for the modeling of correlation within clusters or repeated measures, thus providing more flexibility and accuracy in analyzing real-world data.

  LMMs are particularly useful in addressing challenges such as nested data structures, longitudinal measurements, and variability across subjects or experimental units. By allowing for random effects, such models account for unobserved heterogeneity, making them invaluable in situations where individuals or units differ in ways not captured by the fixed effects alone. This flexibility enhances the model's ability to generalize and improve predictions, making it a versatile tool in both theoretical and applied research.

  Normal Linear Mixed Models (LMMs) have become a fundamental tool in statistical modeling, particularly in hierarchical data structures. LMMs account for both fixed effects, which describe population-level influences and random effects. LMMs are different from other methods such as ANOVA. This flexibility makes them particularly valuable in medical and healthcare research, where patient responses vary.

  The following is hypothetical and will be modified as further direction for the project is taken such as datasets, methodology, design and analysis. The application of LMMs spans various domains, including health-related quality of life assessments, cost predictions, blood pressure monitoring and cardiovascular studies. This paper explores the role of normal linear mixed models in different medical and health research studies. This paper plans to examine advantages of LMMs over other methods such as ANOVA and linear regression. The goal of this paper is to take a data set preferably relating to healthcare and use LMMs to prove their efficiency for a particular data set such as blood pressure data. LMMs would be useful to analyze a blood pressure data set to model patient specific fluctuations. This paper will analyze a blood pressure data set using LMMs to capture circadian rhythms, REM sleep patterns and potential heart issues (hypothetical). 

## Autumn's Literature Review

"Fitting Linear Mixed Models in R" by Douglas Bates. This article provides an in-depth guide on using the lme4 package for fitting linear mixed-effects models in R. Bates discusses the theoretical foundations of mixed-effects models, including fixed and random effects, and shows how to specify and fit these models using the lmer function. The article includes examples and code snippets to illustrate model fitting, interpretation of results, and considerations for model selection and diagnostics. This resource will be valuable for our project by helping us apply mixed-effects modeling techniques in our analyses. [@bates2005fitting]

In full transparency, I was not able to finish reading this article/chapter as it is quite lengthy but the second article/chapter I started reading was Chapter 13 "Linear and Generalized Linear Mixed Models" by Benjamin M. Bolker. From what I've read so far, Bolker provides a very detailed exploration of generalized linear mixed models (GLMM), which combine the characteristics of GLMs and mixed models to deal with a wide range of response variables and grouped data. He discusses the importance of understanding fixed and random effects. He provided several ecological examples (case studies) that included some sort of grouped data that required mixed models. [@bolker2015linear]

"Comparison of linear mixed models for genetic feather score analysis in laying hens kept in recurrent testing facilities" by T. Osorio-Gallardo & P. Bijma.This article discusses a study comparing different models of genetic analysis of feather scores in laying hens, with a focus on the back and neck of these hens at ages 45 and 70 weeks. Feather pecking, feather damage, and mortality are important health and efficiency traits in poultry. Genetic analysis of feather scores can help breed hens with better feather quality reducing feather damage and pecking. This study investigates how genetic parameters can be estimated from sib-group (a group of people/animals who share a common ancestor) data, considering both direct and indirect genetic influences. [@osorio2025comparison]
 
"Determining bad actors: A linear mixed effects model approach to elucidate behavioral toxicity of metal mixtures in drinking water." This study develops a hierarchical modeling approach to identify the "bad actors" in complex metal mixtures that could pose a risk of behavioral toxicity. The researchers used 92 drinking water samples from Maine and New Hampshire which contained multiple metal elements. The study used larval zebrafish to conduct a behavioral assay. This is used for screening large numbers of samples in a high throughput manner, which is a process that can handle a large volume of data or samples very quickly and efficiently. [@dilrukshi2024determining]

Breslow, N. E., & Clayton, D. G. (1993). Approximate Inference in Generalized Linear Mixed Models. Journal of the American Statistical Association, 88(421), 9–25. https://doi.org/10.2307/2290687 The article cited above discusses the use of the generalized linear mixed model (GLMM) framework for addressing overdispersion, correlated errors, shrinkage estimation, and smoothing in regression. GLMMs assume conditionally independent observations given random effects, with means linked to a predictor function and variances specified through a variance function. Random effects follow a normal distribution with unknown variance components. For time series, spatial aggregation, and smoothing problems, dispersion is modeled using a rank-deficient inverse covariance matrix. The estimation process involves approximating marginal quasi-likelihood using Laplace’s method, leading to penalized quasi-likelihood (PQL) for fixed effects and pseudo-likelihood for variance components. Through case studies, the authors demonstrate PQL's utility in hierarchical models. Applications include over dispersion in seed germination rates, longitudinal epilepsy studies, spatial clustering of lip cancer rates, and salamander mating experiments.[@breslow1993approximate] 

Solbu, E. B., van der Veen, B., Herfindal, I., & Hovstad, K. A. (2022). Analyzing dynamic species abundance distributions using generalized linear mixed models. Ecology, 103(9), 1–14. https://www.jstor.org/stable/27189482 This paper explores how generalized linear mixed models (GLMMs) can be used to analyze ecological community dynamics by fitting species abundance distributions. Population dynamic models include key ecological parameters such as environmental noise, demographic variance, long-term growth rate, and density regulation strength, which are crucial for understanding changes in species communities. However, integrating these parameters into community models is complex. The authors propose using intercept-only GLMMs with different random effects to capture species-specific and general responses to environmental stochasticity, spatial variation, and differences in growth rate and carrying capacity. The method is applied to fish and bat communities, demonstrating the estimation of covariance and population dynamic parameters along with their uncertainties. The findings highlight species heterogeneity as the primary driver of spatial and temporal community similarity in both case studies. [@solbu2022analyzing]

## Alex's Literature Review

In cardiovascular research, Gonçalves et al. (2005) highlighted the efficiency of LMMs over ANOVA in analyzing heart rate and coronary-perfused pressure data in transgenic mice. Their study emphasized how LMMs provide a robust and sensitive approach to assessing experimental effects.

Similarly, Matsumoto et al. (2019) used LMMs to analyze sleep disturbances and nocturnal blood pressure profiles in a large-scale population study. They identified lower sleep efficiency as a predictor of reduced nocturnal blood pressure dipping. This was independent of factors like nocturnal urination and sleep-disordered breathing. These findings reinforced the critical role of sleep quality in cardiovascular health.

Edwards & Simpson (2014) used LMMs by incorporating orthonormal polynomials to analyze 24-hour ambulatory blood pressure data. Their methodology enhanced visualization and provided medical experts with clearer insights into blood pressure variations over time.

Finally, Wang et al. (2022) demonstrated the use of LMMs in cardiothoracic surgery outcomes research. By analyzing repeated echocardiographic measurements from patients undergoing pulmonary valve replacement, the study showcased how LMMs handle missing data, model interactions, and address nonlinearity. This largely improved predictive accuracy in clinical research.



## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
