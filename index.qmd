---
title: "Gathering insights about COVID19 Worldwide Testing using Normal Linear Mixed Models"
subtitle: "An analysis of normal linear mixed model algorithms and it's applications"

author: "Autumn Clark and Alex Ottley (Advisor: Dr.Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

[Literature Review](litreview.html){target="_blank"} |
[Slides](slides.html){target="_blank"}


## Introduction

  In recent years, statistical models have become indispensable tools in understanding complex data structures across various fields, including biology, social sciences, economics, and medicine. One powerful class of models that has gained significant traction is the linear mixed model (LMM). Linear mixed models extend traditional linear regression by incorporating both fixed and random effects, making them well-suited for data with hierarchical or grouped structures. Unlike standard linear models, which assume that all observations are independent, linear mixed models allow for the modeling of correlation within clusters or repeated measures, thus providing more flexibility and accuracy in analyzing real-world data.

  LMMs are particularly useful in addressing challenges such as nested data structures, longitudinal measurements, and variability across subjects or experimental units. By allowing for random effects, such models account for unobserved heterogeneity, making them invaluable in situations where individuals or units differ in ways not captured by the fixed effects alone. This flexibility enhances the model's ability to generalize and improve predictions, making it a versatile tool in both theoretical and applied research.

  Normal Linear Mixed Models (LMMs) have become a fundamental tool in statistical modeling, particularly in hierarchical data structures. LMMs account for both fixed effects, which describe population-level influences and random effects. LMMs are different from other methods such as ANOVA. This flexibility makes them particularly valuable in medical and healthcare research, where patient responses vary.

  The following is hypothetical and will be modified as further direction for the project is taken such as datasets, methodology, design and analysis. The application of LMMs spans various domains, including health-related quality of life assessments, cost predictions, blood pressure monitoring and cardiovascular studies. This paper explores the role of normal linear mixed models COVID19 testing done worldwide. This paper plans to examine advantages of LMMs over other methods such as ANOVA and linear regression. The goal of this paper is to take the Covid19 Worldwide Testing dataset and use LMMs to prove their efficiency for a particular data set such as blood pressure data. LMMs would be useful to analyze a blood pressure data set to model patient specific fluctuations. This paper will analyze a blood pressure data set using LMMs to capture circadian rhythms, REM sleep patterns and potential heart issues (hypothetical). 


## Methods

Linear Mixed Model Analysis on repeat measures data set. Furthermore to explain the functionality and uses of Normal Linear Mixed Models. That will likely be the premise of our methods.

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

#### **Dataset Overview:**

Dataset: [Covid19 Worldwide Testing](https://www.kaggle.com/datasets/lin0li/covid19testing/data){target="_blank"}

-   Describe your data sources and collection process.

This dataset, which has the number of tests conducted over time, is important to help making sense of daily reported cases and understanding how COVID-19 is truly spreading in each country.
The world generally uses daily reported positive cases to understand how COVID-19 is spreading in different countries. However, given that potentially over 50% of the cases are asymptomatic, these populations are much less likely to seek testing and get tested. Therefore, the reported cases are highly likely to be only a portion of the population who are truly infected by COVID-19, and the number of reported cases has a strong relation to the number of tests conducted each day.

For example, you can imagine a country not doing much testing might be reporting low number of cases, but it doesn't mean COVID-19 is not spreading in that country. To help making sense of daily reported cases and understanding how COVID-19 is truly spreading in each country, it's crucial to understand how many tests are conducted each day.

##### **Dataset Columns:**

- **Date**: an identifier for each individual
- **Country_Region**: gender of the individual (male or female)
- **Province_State**: age of the individual in years
- **Positive**: cumulative number of positive cases reported
- **Active**: number of active cases on that day
- **Hospitalized**: cumulative number of hospitalized cases reported
- **HospitalizedCurr**: number of actively hospitalized cases on that day
- **Recovered**: cumulative number of recovered cases reported
- **Death**: cumulative number of deaths reported
- **Total_tested**: cumulative number of tests conducted
- **Daily_tested**: number of tests conducted on the day; if daily data is unavailable, daily tested is averaged across of days in
- **Daily_positive**: number of positives cases reported on the day; if daily data is unavailable, daily positive is averaged across number of days in


-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
